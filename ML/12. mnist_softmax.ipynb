{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax를 이용하여 MNIST data set(텐서플로우에 내장된 데이터 셋)을 학습하는 모델을 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "lr = 0.001\n",
    "batch_size = 100\n",
    "training_epochs = 15\n",
    "classes = 10\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "data_train, data_test = mnist.load_data() # train, test set 으로 나누어준다\n",
    "\n",
    "# data, label을 분류해준다\n",
    "(images_train, labels_train) = data_train\n",
    "(images_test, labels_test) = data_test\n",
    "\n",
    "# normalize data\n",
    "\n",
    "images_train, images_test = images_train / 255.0, images_test / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy 모듈의 reshape 를 이용하여 3차원 이미지 데이터를 2차원으로 바꾸어 준다.\n",
    "28 X 28 -> 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original train data shape :  (60000, 28, 28)\n",
      "Original test data shape :  (10000, 28, 28)\n",
      "Reshaped train data shape :  (60000, 784)\n",
      "Reshaped test data shape :  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(\"Original train data shape : \", images_train.shape) # (60000, 28, 28) : 60000개의 28 x 28 이미지 set\n",
    "print(\"Original test data shape : \",images_test.shape) # (10000, 28, 28) : 10000개의 28 x 28 이미지 set\n",
    "\n",
    "images_train = images_train.reshape(images_train.shape[0], images_train.shape[1] * images_train.shape[2])\n",
    "images_test = images_test.reshape(images_test.shape[0], images_test.shape[1] * images_test.shape[2])\n",
    "\n",
    "print(\"Reshaped train data shape : \", images_train.shape)\n",
    "print(\"Reshaped test data shape : \", images_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to_categorical 을 이용하여 10개의 class를 가진 binary class matrix 로 변환해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = tf.keras.utils.to_categorical(labels_train, 10)\n",
    "labels_test = tf.keras.utils.to_categorical(labels_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델을 작성해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.model = tf.keras.Sequential()\n",
    "tf.model.add(tf.keras.layers.Dense(units=10, input_dim=784, activation='softmax'))\n",
    "tf.model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.Adam(0.001),\n",
    "                metrics = ['accuracy'])\n",
    "tf.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.6210 - accuracy: 0.8446\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.3444 - accuracy: 0.9070\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.3083 - accuracy: 0.9149\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.2921 - accuracy: 0.9192\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 2s 39us/sample - loss: 0.2820 - accuracy: 0.9214\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.2748 - accuracy: 0.9234\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2693 - accuracy: 0.9249\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2652 - accuracy: 0.9258\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 2s 36us/sample - loss: 0.2620 - accuracy: 0.9272\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.2592 - accuracy: 0.9281\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 2s 40us/sample - loss: 0.2568 - accuracy: 0.9287\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2550 - accuracy: 0.9294\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 3s 42us/sample - loss: 0.2528 - accuracy: 0.9303\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 2s 38us/sample - loss: 0.2516 - accuracy: 0.9303\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 2s 37us/sample - loss: 0.2498 - accuracy: 0.9314\n"
     ]
    }
   ],
   "source": [
    "train_history = tf.model.fit(images_train, labels_train, batch_size = batch_size, epochs=training_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      " [[1.69536418e-06 1.19608230e-11 4.00157887e-06 ... 9.95500267e-01\n",
      "  1.60791260e-05 2.59078370e-04]\n",
      " [1.70101732e-04 3.01815294e-06 9.93507147e-01 ... 1.27137801e-17\n",
      "  4.88963196e-05 7.45265056e-14]\n",
      " [1.57268494e-06 9.75294590e-01 1.39492871e-02 ... 8.65987211e-04\n",
      "  4.31981869e-03 2.71967641e-04]\n",
      " ...\n",
      " [4.97601693e-09 5.71130254e-09 1.79323354e-06 ... 9.02649073e-04\n",
      "  4.90346784e-03 1.01167755e-02]\n",
      " [9.33383575e-08 3.05358128e-07 1.54970536e-07 ... 1.35331106e-07\n",
      "  7.40677770e-03 1.26624101e-07]\n",
      " [1.33825313e-06 6.53968457e-14 1.00077035e-04 ... 1.32077628e-12\n",
      "  6.87519375e-08 6.98414382e-11]]\n",
      "60000/60000 [==============================] - 5s 83us/sample - loss: 0.2458 - accuracy: 0.9322\n",
      "Accuracy:  0.9322\n"
     ]
    }
   ],
   "source": [
    "pred = tf.model.predict(images_test)\n",
    "print('Prediction: \\n', pred)\n",
    "\n",
    "score = tf.model.evaluate(images_train, labels_train)\n",
    "print('Accuracy: ', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도 : 93.22 %"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
