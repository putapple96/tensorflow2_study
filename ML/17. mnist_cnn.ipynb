{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Conv Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3872)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               495744    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 501,834\n",
      "Trainable params: 501,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "x_test = x_test / 255\n",
    "x_train = x_train / 255\n",
    "\n",
    "tf.model = tf.keras.models.Sequential()\n",
    "\n",
    "# 맨 첫 레이어 이므로 input shape를 지정해준다.\n",
    "# 단, Conv2D는 컬러 채널에 대한 입력까지 받으므로 흑백에 해당되는 1을 세번째 매개변수로 전달.\n",
    "# filter = 해당 Conv2D layer의 채널 수\n",
    "tf.model.add(tf.keras.layers.Conv2D(input_shape=(28, 28, 1), kernel_size=3, filters=16))\n",
    "tf.model.add(tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "tf.model.add(tf.keras.layers.Conv2D(kernel_size=3, filters=32))\n",
    "tf.model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "tf.model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "tf.model.add(tf.keras.layers.Dropout(0.2))\n",
    "tf.model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "tf.model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "tf.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 50s 827us/sample - loss: 0.1746 - accuracy: 0.9474\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 47s 775us/sample - loss: 0.0706 - accuracy: 0.9782\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 47s 786us/sample - loss: 0.0538 - accuracy: 0.9835\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 49s 823us/sample - loss: 0.0439 - accuracy: 0.9862\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 49s 809us/sample - loss: 0.0388 - accuracy: 0.9879\n",
      "10000/10000 [==============================] - 2s 248us/sample - loss: 0.0461 - accuracy: 0.9871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.046101272414460256, 0.9871]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.model.fit(x_train.reshape(-1,28,28,1), y_train, epochs=5)\n",
    "\n",
    "tf.model.evaluate(x_test.reshape(-1,28,28,1), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Conv Layer Model\n",
    "\n",
    "Conv layer를 하나 더 쌓아보자.\n",
    "\n",
    "* ###### 아래와 같이 초기화와 동시에 layer를 쌓아나갈 수 있음.(tf.model.add 보다 훨씬 편함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               73856     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 98,442\n",
      "Trainable params: 98,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(input_shape=(28, 28, 1), kernel_size=3, filters=16),\n",
    "  tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(kernel_size=3, filters=32),\n",
    "  tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "  tf.keras.layers.Conv2D(kernel_size=3, filters=64),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer를 여러번 거치며 image의 크기가 3x3 으로 줄어들었고 이에 따라 학습할 파라미터의 수가 줄어들었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 50s 828us/sample - loss: 0.1738 - accuracy: 0.9465\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 47s 777us/sample - loss: 0.0651 - accuracy: 0.9807- loss: 0.0654 - accura\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 47s 789us/sample - loss: 0.0543 - accuracy: 0.9832\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 46s 766us/sample - loss: 0.0481 - accuracy: 0.9849\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 47s 779us/sample - loss: 0.0411 - accuracy: 0.9874\n",
      "10000/10000 [==============================] - 3s 280us/sample - loss: 0.0355 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.035473667199934424, 0.989]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train.reshape(-1,28,28,1), y_train, epochs=5)\n",
    "model.evaluate(x_test.reshape(-1,28,28,1), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞선 2-Conv Layer 과 퍼포먼스 측면에서 차이가 거의 없다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
